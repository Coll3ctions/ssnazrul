{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json, operator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Class Distribution\n",
    "\n",
    "#### Calculate fraction of documents in each class\n",
    "\n",
    "$$\\pi_j = \\frac{class_{j}}{\\sum\\limits_{n=1}^{20} class_{n} }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of each class:\n",
      "1: 0.04259472890229834\n",
      "2: 0.05155736977549028\n",
      "3: 0.05075871860857219\n",
      "4: 0.05208980388676901\n",
      "5: 0.051024935664211554\n",
      "6: 0.052533498979501284\n",
      "7: 0.051646108794036735\n",
      "8: 0.052533498979501284\n",
      "9: 0.052888455053687104\n",
      "10: 0.0527109770165942\n",
      "11: 0.05306593309078002\n",
      "12: 0.0527109770165942\n",
      "13: 0.05244475996095483\n",
      "14: 0.0527109770165942\n",
      "15: 0.052622237998047744\n",
      "16: 0.05315467210932647\n",
      "17: 0.04836276510781791\n",
      "18: 0.05004880646020055\n",
      "19: 0.04117490460555506\n",
      "20: 0.033365870973467035\n"
     ]
    }
   ],
   "source": [
    "#Training label\n",
    "train_label = open('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/train.label')\n",
    "\n",
    "#pi is the fraction of each class\n",
    "pi = {}\n",
    "\n",
    "#Set a class index for each document as key\n",
    "for i in range(1,21):\n",
    "    pi[i] = 0\n",
    "    \n",
    "#Extract values from training labels\n",
    "lines = train_label.readlines()\n",
    "\n",
    "#Get total number of documents\n",
    "total = len(lines)\n",
    "\n",
    "#Count the occurence of each class\n",
    "for line in lines:\n",
    "    val = int(line.split()[0])\n",
    "    pi[val] += 1\n",
    "\n",
    "#Divide the count of each class by total documents \n",
    "for key in pi:\n",
    "    pi[key] /= total\n",
    "    \n",
    "print(\"Probability of each class:\")\n",
    "print(\"\\n\".join(\"{}: {}\".format(k, v) for k, v in pi.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if sum of the probabilities is 1\n",
    "np.sum(list(pi.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Probability Distribution over V\n",
    "\n",
    "####Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docIdx</th>\n",
       "      <th>wordIdx</th>\n",
       "      <th>count</th>\n",
       "      <th>classIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docIdx  wordIdx  count  classIdx\n",
       "0       1        1      4         1\n",
       "1       1        2      2         1\n",
       "2       1        3     10         1\n",
       "3       1        4      4         1\n",
       "4       1        5      2         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training data\n",
    "train_data = open('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/train.data')\n",
    "df = pd.read_csv(train_data, delimiter=' ', names=['docIdx', 'wordIdx', 'count'])\n",
    "\n",
    "#Training label\n",
    "label = []\n",
    "train_label = open('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/train.label')\n",
    "lines = train_label.readlines()\n",
    "for line in lines:\n",
    "    label.append(int(line.split()[0]))\n",
    "\n",
    "#Increase label length to match docIdx\n",
    "docIdx = df['docIdx'].values\n",
    "i = 0\n",
    "new_label = []\n",
    "for index in range(len(docIdx)-1):\n",
    "    new_label.append(label[i])\n",
    "    if docIdx[index] != docIdx[index+1]:\n",
    "        i += 1\n",
    "new_label.append(label[i]) #for-loop ignores last value\n",
    "\n",
    "#Add label column\n",
    "df['classIdx'] = new_label\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Probability of each word per class\n",
    "\n",
    "For calculating our probability, we will find the average of each word for a given class.\n",
    "\n",
    "For class j and word i, the average is given by:\n",
    "\n",
    "$$P(i|j) = \\frac{word_{ij}}{word_j}$$\n",
    "\n",
    "\n",
    "However, since some words will have 0 counts, we will perform a Laplace Smoothing:\n",
    "\n",
    "\n",
    "\n",
    "$$ P(i|j) = \\frac{word_{ij}+1}{word_j+|V|+1}$$\n",
    "\n",
    "where $V$ is an array of all the words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>wordIdx</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>53966</th>\n",
       "      <th>53967</th>\n",
       "      <th>53968</th>\n",
       "      <th>53969</th>\n",
       "      <th>53970</th>\n",
       "      <th>53971</th>\n",
       "      <th>53972</th>\n",
       "      <th>53973</th>\n",
       "      <th>53974</th>\n",
       "      <th>53975</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classIdx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 53975 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "wordIdx      1         2         3         4         5         6      \\\n",
       "classIdx                                                               \n",
       "1         0.000085  0.000387  0.001668  0.000060  0.000502  0.000254   \n",
       "2         0.000480  0.000472  0.000060  0.000142  0.000118  0.000464   \n",
       "3         0.000112  0.000651  0.000060  0.000168  0.000205  0.000326   \n",
       "4         0.000078  0.000276  0.000060  0.000060  0.000095  0.000423   \n",
       "5         0.000068  0.000330  0.000060  0.000019  0.000019  0.000467   \n",
       "6         0.000283  0.001315  0.000060  0.000472  0.000094  0.000313   \n",
       "7         0.000060  0.000373  0.000060  0.000039  0.000039  0.000424   \n",
       "8         0.000076  0.000421  0.000060  0.000060  0.000107  0.000665   \n",
       "9         0.000126  0.000570  0.000060  0.000042  0.000042  0.000704   \n",
       "10        0.000016  0.000273  0.000060  0.000024  0.000016  0.002432   \n",
       "11        0.000013  0.000430  0.000060  0.000060  0.000013  0.001329   \n",
       "12        0.000244  0.000419  0.000060  0.000055  0.000276  0.000378   \n",
       "13        0.000033  0.000284  0.000060  0.000025  0.000050  0.000259   \n",
       "14        0.000093  0.000233  0.000060  0.000081  0.000122  0.000407   \n",
       "15        0.000288  0.000487  0.000060  0.000135  0.000076  0.000604   \n",
       "16        0.000060  0.000569  0.000078  0.000037  0.000069  0.000468   \n",
       "17        0.000104  0.000177  0.000060  0.000036  0.000062  0.000556   \n",
       "18        0.000041  0.000571  0.000060  0.000037  0.000011  0.000578   \n",
       "19        0.000060  0.000197  0.000060  0.000118  0.000089  0.000748   \n",
       "20        0.000060  0.000339  0.000074  0.000022  0.000177  0.000331   \n",
       "\n",
       "wordIdx      7         8         9         10       ...        53966  \\\n",
       "classIdx                                            ...                \n",
       "1         0.000042  0.000012  0.000211  0.000852    ...     0.000060   \n",
       "2         0.000087  0.000055  0.001362  0.000031    ...     0.000060   \n",
       "3         0.000028  0.000028  0.001349  0.000060    ...     0.000060   \n",
       "4         0.000026  0.000017  0.000423  0.000060    ...     0.000060   \n",
       "5         0.000019  0.000060  0.000467  0.000060    ...     0.000060   \n",
       "6         0.000130  0.000024  0.001404  0.000060    ...     0.000060   \n",
       "7         0.000060  0.000060  0.000373  0.000051    ...     0.000060   \n",
       "8         0.000061  0.000031  0.000145  0.000060    ...     0.000060   \n",
       "9         0.000034  0.000017  0.000042  0.000060    ...     0.000060   \n",
       "10        0.000016  0.000060  0.000024  0.000060    ...     0.000060   \n",
       "11        0.000019  0.000057  0.000032  0.000060    ...     0.000060   \n",
       "12        0.000120  0.000037  0.000516  0.000060    ...     0.000060   \n",
       "13        0.000050  0.000025  0.000250  0.000060    ...     0.000060   \n",
       "14        0.000012  0.000058  0.000151  0.000060    ...     0.000060   \n",
       "15        0.000141  0.000059  0.000147  0.000060    ...     0.000060   \n",
       "16        0.000060  0.000060  0.000083  0.000262    ...     0.000060   \n",
       "17        0.000016  0.000047  0.000104  0.000060    ...     0.000060   \n",
       "18        0.000033  0.000114  0.000041  0.000007    ...     0.000060   \n",
       "19        0.000010  0.000089  0.000054  0.000060    ...     0.000060   \n",
       "20        0.000044  0.000015  0.000147  0.000044    ...     0.000015   \n",
       "\n",
       "wordIdx      53967     53968     53969     53970     53971     53972  \\\n",
       "classIdx                                                               \n",
       "1         0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "2         0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "3         0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "4         0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "5         0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "6         0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "7         0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "8         0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "9         0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "10        0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "11        0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "12        0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "13        0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "14        0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "15        0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "16        0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "17        0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "18        0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "19        0.000060  0.000060  0.000060  0.000060  0.000060  0.000060   \n",
       "20        0.000015  0.000022  0.000015  0.000015  0.000015  0.000015   \n",
       "\n",
       "wordIdx      53973     53974     53975  \n",
       "classIdx                                \n",
       "1         0.000060  0.000060  0.000060  \n",
       "2         0.000060  0.000060  0.000060  \n",
       "3         0.000060  0.000060  0.000060  \n",
       "4         0.000060  0.000060  0.000060  \n",
       "5         0.000060  0.000060  0.000060  \n",
       "6         0.000060  0.000060  0.000060  \n",
       "7         0.000060  0.000060  0.000060  \n",
       "8         0.000060  0.000060  0.000060  \n",
       "9         0.000060  0.000060  0.000060  \n",
       "10        0.000060  0.000060  0.000060  \n",
       "11        0.000060  0.000060  0.000060  \n",
       "12        0.000060  0.000060  0.000060  \n",
       "13        0.000060  0.000060  0.000060  \n",
       "14        0.000060  0.000060  0.000060  \n",
       "15        0.000060  0.000060  0.000060  \n",
       "16        0.000060  0.000060  0.000060  \n",
       "17        0.000060  0.000060  0.000060  \n",
       "18        0.000060  0.000060  0.000060  \n",
       "19        0.000060  0.000060  0.000060  \n",
       "20        0.000015  0.000015  0.000015  \n",
       "\n",
       "[20 rows x 53975 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate probability of each word based on class\n",
    "pb_ij = df.groupby(['classIdx','wordIdx'])\n",
    "pb_j = df.groupby(['classIdx'])\n",
    "Pr =  (pb_ij['count'].sum() + 1) / (pb_j['count'].sum() + 16689)    \n",
    "\n",
    "#Unstack series\n",
    "Pr = Pr.unstack()\n",
    "\n",
    "#Replace NaN or columns with 0 as word count with 1/(|V|+1)\n",
    "Pr = Pr.fillna(1/16689)\n",
    "Pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Multinomial Naive Bayes Classifier\n",
    "\n",
    "Combining probability distribution of P with fraction of documents belonging to each class. \n",
    "\n",
    "For class <b>j</b>, word <b>i</b> at a word frequency of <b>f</b>:\n",
    "\n",
    "$$Pr(j) = \\pi_j \\prod\\limits_{i=1}^{|V|} Pr(i|j)^{f_i}$$\n",
    "\n",
    "In order to avoid underflow, we will use the sum of logs:\n",
    "\n",
    "$$Pr(j) = \\log\\pi_j  + \\sum\\limits_{i=1}^{|V|} f_i\\log(Pr(i|j))$$\n",
    "\n",
    "One issue is that, if a word appears again, the probability of it appearing again goes up. In order to smooth this, we take the log of the frequency:\n",
    "\n",
    "$$Pr(j) = \\log\\pi_j + \\sum\\limits_{i=1}^{|V|} log(1+f_i)\\log(Pr(i|j))$$\n",
    "\n",
    "Also, in order to take stop words into account, we will add an Inverse Document Frequency weight on each word:\n",
    "\n",
    "$$IDF_i = \\log(\\frac{\\sum\\limits_{n=1}^{N} doc_n}{doc_i})$$\n",
    "#### \n",
    "$$Pr(j) = \\log\\pi_j + \\sum\\limits_{i=1}^{|V|} f_i\\log(IDF_iPr(i|j))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Create dictionaries for Word probabilites and Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate IDF\n",
    "tot = len(df['docIdx'].unique())\n",
    "pb_ij = df.groupby(['wordIdx'])\n",
    "IDF = np.log(tot/pb_ij['docIdx'].count())\n",
    "IDF_dict = IDF.to_dict()\n",
    "\n",
    "#Convert to dictionary for greater speed\n",
    "Pr_dict = Pr.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Generating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def MNB(df, smooth = False, IDF = False):\n",
    "    '''\n",
    "    Multinomial Naive Bayes classifier\n",
    "    :param df [Pandas Dataframe]: Dataframe of data\n",
    "    :param smooth [bool]: Apply Smoothing if True\n",
    "    :param IDF [bool]: Apply Inverse Document Frequency if True\n",
    "    :return predict [list]: Predicted class ID\n",
    "    '''\n",
    "    #Using dictionaries for greater speed\n",
    "    df_dict = df.to_dict()\n",
    "    new_dict = {}\n",
    "    prediction = []\n",
    "    \n",
    "    #new_dict = {docIdx : {wordIdx: count},....}\n",
    "    for idx in range(len(df_dict['docIdx'])):\n",
    "        docIdx = df_dict['docIdx'][idx]\n",
    "        wordIdx = df_dict['wordIdx'][idx]\n",
    "        count = df_dict['count'][idx]\n",
    "        try: \n",
    "            new_dict[docIdx][wordIdx] = count \n",
    "        except:\n",
    "            new_dict[df_dict['docIdx'][idx]] = {}\n",
    "            new_dict[docIdx][wordIdx] = count\n",
    "\n",
    "    #Calculating the scores for each doc\n",
    "    for docIdx in range(1, len(new_dict)+1):\n",
    "        score_dict = {}\n",
    "        #Creating a probability row for each class\n",
    "        for classIdx in range(1,21):\n",
    "            score_dict[classIdx] = 1\n",
    "            #For each word:\n",
    "            for wordIdx in new_dict[docIdx]:\n",
    "                #Check for frequency smoothing\n",
    "                #log(1+f)*log(Pr(i|j))\n",
    "                if smooth: \n",
    "                    try:\n",
    "                        probability = Pr_dict[wordIdx][classIdx]         #Pr(i|j)\n",
    "                        power = np.log(1+ new_dict[docIdx][wordIdx])     #log(1+f)\n",
    "                        #Check for IDF\n",
    "                        if IDF:\n",
    "                            score_dict[classIdx] += power*np.log(probability*IDF_dict[wordIdx])\n",
    "                        else:\n",
    "                            score_dict[classIdx] += power*np.log(probability)\n",
    "                    except:\n",
    "                        #Missing V will have (1/16689)^log(1+0)=1 \n",
    "                        score_dict[classIdx] += 0                        \n",
    "                #f*log(Pr(i|j))\n",
    "                else: \n",
    "                    try:\n",
    "                        probability = Pr_dict[wordIdx][classIdx]        #Pr(i|j)\n",
    "                        power = new_dict[docIdx][wordIdx]               #f\n",
    "                        score_dict[classIdx] += power*np.log(probability) \n",
    "                        #Check for IDF\n",
    "                        if IDF:\n",
    "                            score_dict[classIdx] += power*np.log(probability*IDF_dict[wordIdx]) \n",
    "                    except:\n",
    "                        #Missing V will have 0*log(1/16689) = 0\n",
    "                        score_dict[classIdx] += 0       \n",
    "            #Multiply final cumprod with pi         \n",
    "            score_dict[classIdx] +=  np.log(pi[classIdx])                          \n",
    "\n",
    "        #Get class with max probabilty for the given docIdx \n",
    "        max_score = max(score_dict, key=score_dict.get)\n",
    "        prediction.append(max_score)\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Comparing the effects of  Smoothing and IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regular_predict = MNB(df, smooth=False, IDF=False)\n",
    "smooth_predict  = MNB(df, smooth=True, IDF=False)\n",
    "idf_predict     = MNB(df, smooth=False, IDF=True)\n",
    "all_predict     = MNB(df, smooth=True, IDF=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get list of labels\n",
    "train_label = pd.read_csv('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/train.label', names=['t'])\n",
    "train_label= train_label['t'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Score:\t\t 73.99059366403408 %\n",
      "Smooth Score:\t\t 72.14482207826781 %\n",
      "IDF Score:\t\t 74.00834146774336 %\n",
      "Both Score:\t\t 72.14482207826781 %\n"
     ]
    }
   ],
   "source": [
    "total = len(train_label)\n",
    "models = [regular_predict, smooth_predict, idf_predict, all_predict]\n",
    "strings = ['Regular', 'Smooth', 'IDF', 'Both']\n",
    "\n",
    "for m,s in zip(models,strings):\n",
    "    val = 0\n",
    "    for i,j in zip(m, train_label):\n",
    "        if i == j:\n",
    "            val +=1\n",
    "        else:\n",
    "            pass   \n",
    "    print(s,\"Score:\\t\\t\",val/total * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we can see, smoothing makes our model worse while IDF makes the model mode accurate. Hence, our optimal model is:\n",
    "$$Pr(j) = \\log\\pi_j + \\sum\\limits_{i=1}^{|V|} f_i\\log(IDF_iPr(i|j))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:\t 27.55496335776149 %\n"
     ]
    }
   ],
   "source": [
    "#Get test data\n",
    "test_data = open('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/test.data')\n",
    "df = pd.read_csv(test_data, delimiter=' ', names=['docIdx', 'wordIdx', 'count'])\n",
    "\n",
    "#Get list of labels\n",
    "test_label = pd.read_csv('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/test.label', names=['t'])\n",
    "test_label= test_label['t'].tolist()\n",
    "\n",
    "#MNB Calculation\n",
    "predict = MNB(df, smooth = False, IDF = True)\n",
    "\n",
    "total = len(test_label)\n",
    "val = 0\n",
    "for i,j in zip(predict, test_label):\n",
    "    if i == j:\n",
    "        val +=1\n",
    "    else:\n",
    "        pass\n",
    "print(\"Score:\\t\",val/total * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
